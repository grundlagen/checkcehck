{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"14pD85ifqNsxTJdbQucc0VZPkGhwmnuey","authorship_tag":"ABX9TyOCxw1XS3HasfLurx1FFESa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_K9OOOCBtwjH","executionInfo":{"status":"ok","timestamp":1737896783137,"user_tz":0,"elapsed":2489,"user":{"displayName":"Rupert Murphy","userId":"07708960882595328857"}},"outputId":"f80956a2-cbd0-42f1-e42b-3d22a2586657"},"outputs":[{"output_type":"stream","name":"stderr","text":["\n","Generating phoneme sequences:   0%|          | 0/65117 [00:00<?, ?it/s]\u001b[A\n","Generating phoneme sequences:  13%|█▎        | 8660/65117 [00:00<00:01, 54242.98it/s]\u001b[A\n","Generating phoneme sequences: 100%|██████████| 65117/65117 [00:00<00:00, 208499.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Embeddings saved to /content/phoneme_embeddings.txt\n"]}],"source":["import itertools\n","from gensim.models import Word2Vec\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","\n","# Load the phonetic dictionary from the uploaded CSV file\n","# Assuming the delimiter is a tab ('\\t') and the file has a header row\n","df = pd.read_csv('/content/en_UK.txt', delimiter='\\t', header=0)\n","# If the column names are 'aah' and '/ˈɑː/' as in your example:\n","phonetic_dict = dict(zip(df['aah'], df['/ˈɑː/']))\n","# If the column names are different, adjust accordingly\n","\n","# Define articulatory features for phonemes\n","articulatory_features = {\n","    't': {'place': 'alveolar', 'manner': 'stop', 'voicing': 'voiceless'},\n","    'ʔ': {'place': 'glottal', 'manner': 'stop', 'voicing': 'voiceless'},\n","    'd': {'place': 'alveolar', 'manner': 'stop', 'voicing': 'voiced'},\n","    's': {'place': 'alveolar', 'manner': 'fricative', 'voicing': 'voiceless'},\n","    'z': {'place': 'alveolar', 'manner': 'fricative', 'voicing': 'voiced'},\n","    'ə': {'place': 'central', 'manner': 'vowel', 'voicing': 'voiced'},\n","    'ʃ': {'place': 'postalveolar', 'manner': 'fricative', 'voicing': 'voiceless'},\n","    'ʒ': {'place': 'postalveolar', 'manner': 'fricative', 'voicing': 'voiced'},\n","    'p': {'place': 'bilabial', 'manner': 'stop', 'voicing': 'voiceless'},\n","    'b': {'place': 'bilabial', 'manner': 'stop', 'voicing': 'voiced'},\n","    'k': {'place': 'velar', 'manner': 'stop', 'voicing': 'voiceless'},\n","    'g': {'place': 'velar', 'manner': 'stop', 'voicing': 'voiced'},\n","    'f': {'place': 'labiodental', 'manner': 'fricative', 'voicing': 'voiceless'},\n","    'v': {'place': 'labiodental', 'manner': 'fricative', 'voicing': 'voiced'},\n","    'θ': {'place': 'dental', 'manner': 'fricative', 'voicing': 'voiceless'},\n","    'ð': {'place': 'dental', 'manner': 'fricative', 'voicing': 'voiced'},\n","    'm': {'place': 'bilabial', 'manner': 'nasal', 'voicing': 'voiced'},\n","    'n': {'place': 'alveolar', 'manner': 'nasal', 'voicing': 'voiced'},\n","    'ŋ': {'place': 'velar', 'manner': 'nasal', 'voicing': 'voiced'},\n","    'h': {'place': 'glottal', 'manner': 'fricative', 'voicing': 'voiceless'},\n","    'j': {'place': 'palatal', 'manner': 'approximant', 'voicing': 'voiced'},\n","    'w': {'place': 'labio-velar', 'manner': 'approximant', 'voicing': 'voiced'},\n","    'r': {'place': 'alveolar', 'manner': 'approximant', 'voicing': 'voiced'},\n","    'l': {'place': 'alveolar', 'manner': 'lateral approximant', 'voicing': 'voiced'},\n","    # Add more phonemes...\n","}\n","\n","# Phoneme mapping between similar sounds\n","phoneme_mapping = {\n","    'i': ['i', 'ɪ'],\n","    'ɪ': ['i', 'ɪ'],\n","    'eɪ': ['e', 'eɪ'],\n","    'ɛ': ['ɛ', 'e'],\n","    'æ': ['a', 'æ'],\n","    'ɑ': ['a', 'ɑ'],\n","    'ɔ': ['o', 'ɔ'],\n","    'ə': ['ə', 'ʌ'],\n","    'ʌ': ['ə', 'ʌ'],\n","    't': ['t', 'ʔ', 'ɾ'],\n","    'd': ['t', 'ɾ'],\n","    's': ['s', 'z'],\n","    'z': ['s', 'z'],\n","    'ʃ': ['ʃ', 'ʒ'],\n","    'ʒ': ['ʃ', 'ʒ'],\n","    'n': ['n', 'ŋ'],\n","    'ŋ': ['n', 'ŋ'],\n","    'l': ['l', 'ɫ'],\n","    'r': ['r', 'ɹ'],\n","    'p': ['p', 'b'],\n","    'b': ['p', 'b'],\n","    'k': ['k', 'g'],\n","    'g': ['k', 'g'],\n","    'f': ['f', 'v'],\n","    'v': ['f', 'v'],\n","    'θ': ['θ', 'ð'],\n","    'ð': ['θ', 'ð'],\n","    'h': ['h', 'ʔ'],\n","    'w': ['w', 'v'],\n","    # Add more based on phonetic similarities\n","}\n","\n","# Function to extract phonemes from a word using the phonetic dictionary\n","def get_phonemes(word):\n","    return phonetic_dict.get(word.lower(), '')\n","\n","# Function to save embeddings to a text file\n","def save_embeddings_to_file(model, output_path):\n","    with open(output_path, 'w', encoding='utf-8') as file:\n","        for word in model.wv.index_to_key:\n","            embedding = model.wv[word]\n","            embedding_str = ','.join(map(str, embedding))\n","            file.write(f\"{word}\\t{embedding_str}\\n\")\n","\n","# Function to train Word2Vec on phoneme sequences and save embeddings\n","def train_and_save_embeddings(vocabulary, output_path):\n","    phoneme_sequences = [list(get_phonemes(word)) for word in tqdm(vocabulary, desc=\"Generating phoneme sequences\")]\n","    phoneme_sequences = [seq for seq in phoneme_sequences if seq]  # Filter empty sequences\n","    model = Word2Vec(phoneme_sequences, vector_size=100, window=5, min_count=1, workers=4)\n","    save_embeddings_to_file(model, output_path)\n","\n","# Vocabulary for embedding training\n","vocabulary = [str(word) for word in phonetic_dict.keys()]  # Convert keys to strings\n","\n","# Train embeddings and save to file\n","embedding_output_path = '/content/phoneme_embeddings.txt'\n","train_and_save_embeddings(vocabulary, embedding_output_path)\n","\n","# Notify completion\n","print(f\"Embeddings saved to {embedding_output_path}\")\n"]},{"cell_type":"code","source":["import itertools\n","from gensim.models import Word2Vec\n","import pandas as pd\n","from tqdm import tqdm\n","\n","# Load the English phonetic dictionary\n","english_df = pd.read_csv('/content/en_UK.txt', delimiter='\\t', header=0)\n","english_phonetic_dict = dict(zip(english_df['aah'], english_df['/ˈɑː/']))\n","\n","# Load the French phonetic dictionary\n","french_df = pd.read_csv('/content/fr_FR.txt', delimiter='\\t', header=0)\n","# The column names in the French dataframe were 'a' and '/a/' respectively instead of 'word' and 'phonetic'\n","french_phonetic_dict = dict(zip(french_df['a'], french_df['/a/']))  # Changed to the actual column names\n","\n","# Combine dictionaries into a single dataset for embedding training\n","def combine_phonetic_dicts(en_dict, fr_dict):\n","    combined = []\n","    for word, phonemes in en_dict.items():\n","        combined.append(list(phonemes))\n","    for word, phonemes in fr_dict.items():\n","        combined.append(list(phonemes))\n","    return combined\n","\n","# Train Word2Vec on phoneme sequences and save embeddings\n","def train_and_save_embeddings(phoneme_sequences, output_path):\n","    model = Word2Vec(phoneme_sequences, vector_size=100, window=5, min_count=1, workers=4)\n","    with open(output_path, 'w', encoding='utf-8') as file:\n","        for word in model.wv.index_to_key:\n","            embedding = model.wv[word]\n","            embedding_str = ','.join(map(str, embedding))\n","            file.write(f\"{word}\\t{embedding_str}\\n\")\n","\n","# Generate phoneme sequences from the combined dataset\n","phoneme_sequences = combine_phonetic_dicts(english_phonetic_dict, french_phonetic_dict)\n","\n","# Output file for embeddings\n","embedding_output_path = '/content/phoneme_embeddings_combined.txt'\n","\n","# Train and save embeddings\n","train_and_save_embeddings(phoneme_sequences, embedding_output_path)\n","\n","# Notify completion\n","print(f\"Embeddings for English and French saved to {embedding_output_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q8FwmrRmvxNk","executionInfo":{"status":"ok","timestamp":1737897296135,"user_tz":0,"elapsed":8505,"user":{"displayName":"Rupert Murphy","userId":"07708960882595328857"}},"outputId":"bb4aea1e-78e3-43ac-9c71-49b981795a74"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["\rGenerating phoneme sequences:  57%|█████▋    | 37235/65117 [09:14<06:55, 67.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Embeddings for English and French saved to /content/phoneme_embeddings_combined.txt\n"]}]},{"cell_type":"code","source":["import itertools\n","from gensim.models import Word2Vec\n","import pandas as pd\n","from tqdm import tqdm\n","\n","# Load linguistic rules and phoneme mappings\n","with open('/content/linguistic_rules_and_mappings (1).txt', 'r') as file:\n","    exec(file.read())\n","\n","# Load the English phonetic dictionary\n","english_df = pd.read_csv('/content/en_UK.txt', delimiter='\\t', header=0)\n","english_phonetic_dict = dict(zip(english_df['aah'], english_df['/ˈɑː/']))\n","\n","# Load the French phonetic dictionary\n","french_df = pd.read_csv('/content/fr_FR.txt', delimiter='\\t', header=0)\n","# The column names in the French dataframe were 'a' and '/a/' respectively instead of 'word' and 'phonetic'\n","# Changed to the actual column names: 'a' and '/a/'\n","french_phonetic_dict = dict(zip(french_df['a'], french_df['/a/']))\n","\n","# Expand phoneme sequences using phoneme_mapping\n","def expand_phoneme_sequence(sequence):\n","    expanded = []\n","    for phoneme in sequence:\n","        variants = phoneme_mapping.get(phoneme, [phoneme])\n","        expanded.extend(variants)\n","    return expanded\n","\n","# Combine dictionaries into a single dataset for embedding training\n","def combine_phonetic_dicts(en_dict, fr_dict):\n","    combined = []\n","    for word, phonemes in en_dict.items():\n","        expanded_phonemes = expand_phoneme_sequence(phonemes)\n","        combined.append(expanded_phonemes)\n","    for word, phonemes in fr_dict.items():\n","        expanded_phonemes = expand_phoneme_sequence(phonemes)\n","        combined.append(expanded_phonemes)\n","    return combined\n","\n","# Train Word2Vec on phoneme sequences and save embeddings\n","def train_and_save_embeddings(phoneme_sequences, output_path):\n","    model = Word2Vec(phoneme_sequences, vector_size=100, window=5, min_count=1, workers=4)\n","    with open(output_path, 'w', encoding='utf-8') as file:\n","        for word in model.wv.index_to_key:\n","            embedding = model.wv[word]\n","            embedding_str = ','.join(map(str, embedding))\n","            file.write(f\"{word}\\t{embedding_str}\\n\")\n","\n","# Generate phoneme sequences from the combined dataset\n","phoneme_sequences = combine_phonetic_dicts(english_phonetic_dict, french_phonetic_dict)\n","\n","# Output file for embeddings\n","embedding_output_path = '/content/phoneme_embeddings_combined_expanded.txt'\n","\n","# Train and save embeddings\n","train_and_save_embeddings(phoneme_sequences, embedding_output_path)\n","\n","# Notify completion\n","print(f\"Embeddings for English and French with expanded mappings saved to {embedding_output_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iwhQeEQnw1WN","executionInfo":{"status":"ok","timestamp":1737897574821,"user_tz":0,"elapsed":20422,"user":{"displayName":"Rupert Murphy","userId":"07708960882595328857"}},"outputId":"5b790e18-90db-4f03-a313-c521b180c462"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Embeddings for English and French with expanded mappings saved to /content/phoneme_embeddings_combined_expanded.txt\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from tqdm import tqdm\n","\n","# Load embeddings from file\n","embedding_file_path = \"/content/phoneme_embeddings_combined_expanded.txt\"\n","embeddings = {}\n","\n","with open(embedding_file_path, 'r', encoding='utf-8') as file:\n","    for line in file:\n","        parts = line.strip().split('\\t')\n","        if len(parts) == 2:\n","            phoneme, embedding_str = parts\n","            embedding = np.array([float(value) for value in embedding_str.split(',')])\n","            embeddings[phoneme] = embedding\n","\n","# Function to calculate cosine similarity between two vectors\n","def cosine_similarity(vec1, vec2):\n","    dot_product = np.dot(vec1, vec2)\n","    norm1 = np.linalg.norm(vec1)\n","    norm2 = np.linalg.norm(vec2)\n","    return dot_product / (norm1 * norm2)\n","\n","# Generate iterative phoneme strings based on embeddings\n","def generate_iterative_strings(embeddings, threshold=0.85):\n","    phoneme_list = list(embeddings.keys())\n","    results = []\n","\n","    for i, phoneme1 in enumerate(tqdm(phoneme_list, desc=\"Generating strings\")):\n","        for phoneme2 in phoneme_list[i+1:]:\n","            similarity = cosine_similarity(embeddings[phoneme1], embeddings[phoneme2])\n","            if similarity >= threshold:\n","                results.append((phoneme1, phoneme2, similarity))\n","\n","    return results\n","\n","# Run iterative string generation\n","results = generate_iterative_strings(embeddings)\n","\n","# Save results to a file\n","output_file_path = \"C:\\\\Users\\\\Lenovo\\\\Downloads\\\\phoneme_string_matches.txt\"\n","with open(output_file_path, 'w', encoding='utf-8') as output_file:\n","    for phoneme1, phoneme2, similarity in results:\n","        output_file.write(f\"{phoneme1}\\t{phoneme2}\\t{similarity:.4f}\\n\")\n","\n","print(f\"Generated phoneme string matches saved to {output_file_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h6xdITuYzUtu","executionInfo":{"status":"ok","timestamp":1737898167569,"user_tz":0,"elapsed":234,"user":{"displayName":"Rupert Murphy","userId":"07708960882595328857"}},"outputId":"5f3534c3-ad0a-4d79-f6c9-36309e97975e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["Generating strings: 100%|██████████| 74/74 [00:00<00:00, 4075.72it/s]"]},{"output_type":"stream","name":"stdout","text":["Generated phoneme string matches saved to C:\\Users\\Lenovo\\Downloads\\phoneme_string_matches.txt\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}