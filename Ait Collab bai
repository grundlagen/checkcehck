{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26522,"status":"ok","timestamp":1705658884157,"user":{"displayName":"Rupert Murphy","userId":"07708960882595328857"},"user_tz":0},"id":"VH5ohsY1oTPX","outputId":"61f3540b-b40d-4eed-f63a-608cf5704b8b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting vosk\n","  Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from vosk) (1.16.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vosk) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from vosk) (4.66.1)\n","Collecting srt (from vosk)\n","  Downloading srt-3.5.3.tar.gz (28 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting websockets (from vosk)\n","  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->vosk) (2.21)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (2023.11.17)\n","Building wheels for collected packages: srt\n","  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22428 sha256=94f81ca740205887a39754f46f03e554cae8f00418a06743233b280e2ea7324a\n","  Stored in directory: /root/.cache/pip/wheels/d7/31/a1/18e1e7e8bfdafd19e6803d7eb919b563dd11de380e4304e332\n","Successfully built srt\n","Installing collected packages: websockets, srt, vosk\n","Successfully installed srt-3.5.3 vosk-0.3.45 websockets-12.0\n","Collecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub\n","Successfully installed pydub-0.25.1\n"]}],"source":["!pip install vosk\n","!pip install pydub"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5yNiDodFRS5F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"error","timestamp":1705437676417,"user_tz":0,"elapsed":38,"user":{"displayName":"Rupert Murphy","userId":"07708960882595328857"}},"outputId":"cdccc208-a436-4f4b-a02a-eec59c0df3d0"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'metaphone'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-1b51fd977223>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmetaphone\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdoublemetaphone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'metaphone'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import csv\n","from metaphone import doublemetaphone\n","from tqdm import tqdm\n","import datetime\n","\n","# Function to perform phonetic matching\n","def phonetic_matching(english_words, french_words, threshold=0.95):  # Increase threshold for stricter matching\n","    potential_matches = []\n","    for eng_word in tqdm(english_words, desc=\"Phonetic Matching\"):\n","        eng_phonetic = doublemetaphone(eng_word)\n","        for fr_word in french_words:\n","            fr_phonetic = doublemetaphone(fr_word)\n","            if eng_phonetic == fr_phonetic:\n","                potential_matches.append((eng_word, fr_word))\n","    return potential_matches\n","\n","# Read data from the CSV file\n","input_file = \"phonetic_matches.csv\"\n","with open(input_file, 'r', newline='', encoding='utf-8') as file:\n","    reader = csv.reader(file)\n","    next(reader)  # Skip the header row\n","    data = list(reader)\n","\n","# Extract English and French words from the CSV data\n","english_words = [row[0] for row in data]\n","french_words = [row[1] for row in data]\n","\n","# Perform phonetic matching\n","potential_matches = phonetic_matching(english_words, french_words)\n","\n","# Generate a unique output file name\n","output_file = generate_output_filename()\n","\n","# Save potential matches to file\n","with open(output_file, 'w', newline='', encoding='utf-8') as file:\n","    writer = csv.writer(file)\n","    writer.writerow([\"English Word\", \"French Word\"])  # Header\n","    for match in potential_matches:\n","        writer.writerow(match)\n","\n","print(\"Phonetic matching completed. Results saved to:\", output_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R44rCMU8RUMD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704657867024,"user_tz":0,"elapsed":1268,"user":{"displayName":"Rupert Murphy","userId":"07708960882595328857"}},"outputId":"fca477c3-48e2-41c9-c9e3-520b58e150e4"},"outputs":[{"output_type":"stream","name":"stderr","text":["Phonetic Matching: 0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Phonetic matching completed. Results saved to: phonetic_matches_20240107200425.csv\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import csv\n","from metaphone import doublemetaphone\n","from tqdm import tqdm\n","import datetime\n","\n","# Function to perform phonetic matching\n","def phonetic_matching(english_words, french_words, threshold=0.95):  # Increase threshold for stricter matching\n","    potential_matches = []\n","    for eng_word in tqdm(english_words, desc=\"Phonetic Matching\"):\n","        eng_phonetic = doublemetaphone(eng_word)\n","        for fr_word in french_words:\n","            fr_phonetic = doublemetaphone(fr_word)\n","            if eng_phonetic == fr_phonetic:\n","                potential_matches.append((eng_word, fr_word))\n","    return potential_matches\n","\n","# Read data from the CSV file\n","input_file = \"phonetic_matches.csv\"\n","with open(input_file, 'r', newline='', encoding='utf-8') as file:\n","    reader = csv.reader(file)\n","    next(reader)  # Skip the header row\n","    data = list(reader)\n","\n","# Extract English and French words from the CSV data\n","english_words = [row[0] for row in data]\n","french_words = [row[1] for row in data]\n","\n","# Perform phonetic matching\n","potential_matches = phonetic_matching(english_words, french_words)\n","\n","# Generate a unique output file name with timestamp\n","timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n","output_file = f\"phonetic_matches_{timestamp}.csv\"\n","\n","# Save potential matches to file\n","with open(output_file, 'w', newline='', encoding='utf-8') as file:\n","    writer = csv.writer(file)\n","    writer.writerow([\"English Word\", \"French Word\"])  # Header\n","    for match in potential_matches:\n","        writer.writerow(match)\n","\n","print(\"Phonetic matching completed. Results saved to:\", output_file)"]},{"cell_type":"code","source":[],"metadata":{"id":"w2Vk_OFAidBE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q3iqK7ZVRiXU"},"source":["# New Section"]},{"cell_type":"markdown","metadata":{"id":"cbJvvh4QRi-Q"},"source":["# New Section"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l1YwDMspS5qk"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20985,"status":"ok","timestamp":1704651220382,"user":{"displayName":"Rupert Murphy","userId":"07708960882595328857"},"user_tz":0},"id":"w6xwNPoXIP-n","outputId":"e047c321-56b7-4e22-e7a0-68d11c9baeef"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting vosk\n","  Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from vosk) (1.16.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vosk) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from vosk) (4.66.1)\n","Collecting srt (from vosk)\n","  Downloading srt-3.5.3.tar.gz (28 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting websockets (from vosk)\n","  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->vosk) (2.21)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (2023.11.17)\n","Building wheels for collected packages: srt\n","  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22428 sha256=d7054ea1d441fc4d5685e7347264031da00b25b96d3fba36c0219ec57c24ade6\n","  Stored in directory: /root/.cache/pip/wheels/d7/31/a1/18e1e7e8bfdafd19e6803d7eb919b563dd11de380e4304e332\n","Successfully built srt\n","Installing collected packages: websockets, srt, vosk\n","Successfully installed srt-3.5.3 vosk-0.3.45 websockets-12.0\n"]}],"source":["!pip install vosk"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":613},"executionInfo":{"elapsed":32,"status":"error","timestamp":1704651224676,"user":{"displayName":"Rupert Murphy","userId":"07708960882595328857"},"user_tz":0},"id":"rn_b83F0IWGU","outputId":"02aa4288-1396-4330-da73-f5e37536ffb3"},"outputs":[{"ename":"Exception","evalue":"Failed to create a model","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-4f39fc83cb80>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the Vosk models for English and French\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0menglish_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvosk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vosk-model-english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mfrench_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvosk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vosk-model-french\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vosk/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_path, model_name, lang)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvosk_model_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNULL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to create a model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mException\u001b[0m: Failed to create a model"]}],"source":["import vosk\n","import wave\n","\n","# Load the Vosk models for English and French\n","english_model = vosk.Model(\"vosk-model-english\")\n","french_model = vosk.Model(\"vosk-model-french\")\n","\n","# Specify the path to your downloaded audio file (replace \"your_audio_file.wav\" with the actual filename)\n","audio_file = \"your_audio_file.wav\"\n","\n","# Open the audio file\n","wf = wave.open(audio_file, \"rb\")\n","\n","# Initialize the Vosk recognizers\n","english_recognizer = vosk.KaldiRecognizer(english_model, wf.getframerate())\n","french_recognizer = vosk.KaldiRecognizer(french_model, wf.getframerate())\n","\n","# Transcribe and extract recognized units with timestamps\n","english_units = []\n","french_units = []\n","\n","while True:\n","    data = wf.readframes(4000)  # Adjust frame size as needed\n","    if len(data) == 0:\n","        break\n","    english_recognizer.AcceptWaveform(data)\n","    french_recognizer.AcceptWaveform(data)\n","\n","# Get recognized units with timestamps\n","english_units = english_recognizer.Result()\n","french_units = french_recognizer.Result()\n","\n","# Now you have recognized units for both English and French along with timestamps\n","# Implement matching based on timestamps and handling nuances into this code."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8qq-pGiOJQbC","outputId":"db833d2f-78b0-4772-f77e-148f05605668"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n"]}],"source":["!pip install pydub"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16484,"status":"ok","timestamp":1704653664091,"user":{"displayName":"Rupert Murphy","userId":"07708960882595328857"},"user_tz":0},"id":"RP09RbMCJSxs","outputId":"e65a05e9-1595-4a17-845f-f200d9832f28"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting Metaphone\n","  Downloading Metaphone-0.6.tar.gz (14 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting rapidfuzz\n","  Downloading rapidfuzz-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n","Building wheels for collected packages: Metaphone\n","  Building wheel for Metaphone (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for Metaphone: filename=Metaphone-0.6-py3-none-any.whl size=13902 sha256=895856dca452ac6bb1502eaaa220a43ffd7d3bc54ed3f8fee9a88c6291f4010c\n","  Stored in directory: /root/.cache/pip/wheels/23/dd/1d/6cdd346605db62bde1f60954155e9ce48f4681c243f265b704\n","Successfully built Metaphone\n","Installing collected packages: Metaphone, rapidfuzz\n","Successfully installed Metaphone-0.6 rapidfuzz-3.6.1\n","Error during matching: 'set' object is not subscriptable\n","Phonetic matching completed. Results saved to: phonetic_matches.csv\n"]}],"source":["\n","# Install necessary libraries\n","!pip install Metaphone rapidfuzz tqdm\n","\n","import requests\n","import csv\n","from metaphone import doublemetaphone\n","from rapidfuzz import fuzz\n","from tqdm import tqdm\n","\n","# Function to fetch word lists\n","def fetch_words(url):\n","    response = requests.get(url)\n","    if response.status_code == 200:\n","        return response.text.splitlines()\n","    return []\n","\n","# Improved pre-filtering: Exclude non-matching starting letters and similar length\n","def prefilter_words(english_words, french_words):\n","    filtered_english = set(english_words)\n","    filtered_french = set(word for word in french_words if word[0] in filtered_english and 3 < len(word) < 15)\n","    return filtered_english, filtered_french\n","\n","# Modified approximate_matching function with match count monitoring and error handling\n","def approximate_matching(english_words, french_words, top_n=50000, threshold=70, batch_size=10000):\n","    potential_matches = []\n","    try:\n","        for i in range(0, len(english_words), batch_size):\n","            batch = english_words[i:i+batch_size]\n","            for eng_word in tqdm(batch, desc=f\"Batch {i//batch_size+1}\"):\n","                best_match = (None, 0)  # Tuple of (word, score)\n","                for fr_word in french_words:\n","                    if eng_word[0] != fr_word[0]:\n","                        continue\n","                    similarity_ratio = fuzz.ratio(eng_word, fr_word)\n","                    if similarity_ratio > best_match[1]:\n","                        best_match = (fr_word, similarity_ratio)\n","                if best_match[1] >= threshold:\n","                    potential_matches.append((eng_word, best_match[0], best_match[1]))\n","                    if len(potential_matches) >= top_n:\n","                        print(f\"Top {top_n} matches limit reached.\")\n","                        return potential_matches\n","        print(f\"All words processed. Total matches found: {len(potential_matches)}\")\n","    except Exception as e:\n","        print(f\"Error during matching: {e}\")\n","    return potential_matches\n","\n","# URLs for English and French word lists\n","english_words_url = \"https://raw.githubusercontent.com/dwyl/english-words/master/words.txt\"\n","french_words_url = \"https://raw.githubusercontent.com/Taknok/French-Wordlist/master/francais.txt\"\n","\n","# Fetch word lists\n","english_words = fetch_words(english_words_url)\n","french_words = fetch_words(french_words_url)\n","\n","# Pre-filter words\n","english_words, french_words = prefilter_words(english_words, french_words)\n","\n","# Perform approximate matching\n","potential_matches = approximate_matching(english_words, french_words)\n","\n","# File to save matches\n","output_file = \"phonetic_matches.csv\"\n","\n","# Save potential matches to file\n","with open(output_file, 'w', newline='', encoding='utf-8') as file:\n","    writer = csv.writer(file)\n","    writer.writerow([\"English Word\", \"French Word\", \"Similarity Score\"])  # Header\n","    for match in potential_matches:\n","        writer.writerow(match)\n","\n","print(\"Phonetic matching completed. Results saved to:\", output_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":575},"executionInfo":{"elapsed":282597,"status":"ok","timestamp":1704654372541,"user":{"displayName":"Rupert Murphy","userId":"07708960882595328857"},"user_tz":0},"id":"evkPqvugS7d6","outputId":"7d8677f2-617e-4ad5-b6e5-8437a695458c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: Metaphone in /usr/local/lib/python3.10/dist-packages (0.6)\n","Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (3.6.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n"]},{"name":"stderr","output_type":"stream","text":["Batch 1: 100%|██████████| 10000/10000 [00:13<00:00, 758.84it/s]\n","Batch 2: 100%|██████████| 10000/10000 [00:13<00:00, 745.27it/s]\n","Batch 3: 100%|██████████| 10000/10000 [00:13<00:00, 756.23it/s]\n","Batch 4: 100%|██████████| 10000/10000 [00:08<00:00, 1168.99it/s]\n","Batch 5: 100%|██████████| 10000/10000 [00:08<00:00, 1249.35it/s]\n","Batch 6: 100%|██████████| 10000/10000 [00:06<00:00, 1453.35it/s]\n","Batch 7: 100%|██████████| 10000/10000 [00:08<00:00, 1249.31it/s]\n","Batch 8: 100%|██████████| 10000/10000 [00:06<00:00, 1468.56it/s]\n","Batch 9: 100%|██████████| 10000/10000 [00:07<00:00, 1253.32it/s]\n","Batch 10: 100%|██████████| 10000/10000 [00:08<00:00, 1237.80it/s]\n","Batch 11: 100%|██████████| 10000/10000 [00:06<00:00, 1487.59it/s]\n","Batch 12: 100%|██████████| 10000/10000 [00:07<00:00, 1266.75it/s]\n","Batch 13: 100%|██████████| 10000/10000 [00:06<00:00, 1479.90it/s]\n","Batch 14: 100%|██████████| 10000/10000 [00:07<00:00, 1265.83it/s]\n","Batch 15: 100%|██████████| 10000/10000 [00:07<00:00, 1268.43it/s]\n","Batch 16: 100%|██████████| 10000/10000 [00:06<00:00, 1476.26it/s]\n","Batch 17: 100%|██████████| 10000/10000 [00:08<00:00, 1246.90it/s]\n","Batch 18: 100%|██████████| 10000/10000 [00:07<00:00, 1409.25it/s]\n","Batch 19: 100%|██████████| 10000/10000 [00:09<00:00, 1026.63it/s]\n","Batch 20: 100%|██████████| 10000/10000 [00:10<00:00, 914.17it/s]\n","Batch 21: 100%|██████████| 10000/10000 [00:08<00:00, 1245.51it/s]\n","Batch 22: 100%|██████████| 10000/10000 [00:06<00:00, 1463.94it/s]\n","Batch 23: 100%|██████████| 10000/10000 [00:09<00:00, 1038.84it/s]\n","Batch 24: 100%|██████████| 10000/10000 [00:11<00:00, 877.24it/s]\n","Batch 25: 100%|██████████| 10000/10000 [00:11<00:00, 883.85it/s]\n","Batch 26:   8%|▊         | 836/10000 [00:00<00:07, 1276.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Top 50000 matches limit reached.\n","Phonetic matching completed. Results saved to: phonetic_matches.csv\n"]},{"data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["download(\"download_57fbf7c8-b6a8-4b86-9975-dde1f684eb23\", \"phonetic_matches.csv\", 1666213)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["# Install necessary libraries\n","!pip install Metaphone rapidfuzz tqdm\n","\n","import requests\n","import csv\n","from metaphone import doublemetaphone\n","from rapidfuzz import fuzz\n","from tqdm import tqdm\n","\n","# Function to fetch word lists\n","def fetch_words(url):\n","    response = requests.get(url)\n","    if response.status_code == 200:\n","        return response.text.splitlines()\n","    return []\n","\n","# Improved pre-filtering: Exclude non-matching starting letters and similar length\n","def prefilter_words(english_words, french_words):\n","    filtered_english = list(english_words)  # Convert to list\n","    filtered_french = list(word for word in french_words if word[0] in filtered_english and 3 < len(word) < 15)\n","    return filtered_english, filtered_french\n","\n","# Modified approximate_matching function with match count monitoring and error handling\n","def approximate_matching(english_words, french_words, top_n=50000, threshold=70, batch_size=10000):\n","    potential_matches = []\n","    try:\n","        for i in range(0, len(english_words), batch_size):\n","            batch = english_words[i:i+batch_size]\n","            for eng_word in tqdm(batch, desc=f\"Batch {i//batch_size+1}\"):\n","                best_match = (None, 0)  # Tuple of (word, score)\n","                for fr_word in french_words:\n","                    if eng_word[0] != fr_word[0]:\n","                        continue\n","                    similarity_ratio = fuzz.ratio(eng_word, fr_word)\n","                    if similarity_ratio > best_match[1]:\n","                        best_match = (fr_word, similarity_ratio)\n","                if best_match[1] >= threshold:\n","                    potential_matches.append((eng_word, best_match[0], best_match[1]))\n","                    if len(potential_matches) >= top_n:\n","                        print(f\"Top {top_n} matches limit reached.\")\n","                        return potential_matches\n","        print(f\"All words processed. Total matches found: {len(potential_matches)}\")\n","    except Exception as e:\n","        print(f\"Error during matching: {e}\")\n","    return potential_matches\n","\n","# URLs for English and French word lists\n","english_words_url = \"https://raw.githubusercontent.com/dwyl/english-words/master/words.txt\"\n","french_words_url = \"https://raw.githubusercontent.com/Taknok/French-Wordlist/master/francais.txt\"\n","\n","# Fetch word lists\n","english_words = fetch_words(english_words_url)\n","french_words = fetch_words(french_words_url)\n","\n","# Pre-filter words\n","english_words, french_words = prefilter_words(english_words, french_words)\n","\n","# Perform approximate matching\n","potential_matches = approximate_matching(english_words, french_words)\n","\n","# File to save matches\n","output_file = \"phonetic_matches.csv\"\n","\n","# Save potential matches to file\n","with open(output_file, 'w', newline='', encoding='utf-8') as file:\n","    writer = csv.writer(file)\n","    writer.writerow([\"English Word\", \"French Word\", \"Similarity Score\"])  # Header\n","    for match in potential_matches:\n","        writer.writerow(match)\n","\n","print(\"Phonetic matching completed. Results saved to:\", output_file)\n","\n","# Download CSV file\n","from google.colab import files\n","files.download(output_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24718,"status":"ok","timestamp":1705524848308,"user":{"displayName":"Rupert Murphy","userId":"07708960882595328857"},"user_tz":0},"id":"cbcoT_MSVKcK","outputId":"629bf6b2-2acf-4824-b5b7-9aef4288ccc2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting Metaphone\n","  Downloading Metaphone-0.6.tar.gz (14 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting rapidfuzz\n","  Downloading rapidfuzz-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n","Building wheels for collected packages: Metaphone\n","  Building wheel for Metaphone (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for Metaphone: filename=Metaphone-0.6-py3-none-any.whl size=13902 sha256=26a2b5a4bde56c7be0e817014a3f37ec37f74a5017e5b9738648ad89ba41fa03\n","  Stored in directory: /root/.cache/pip/wheels/23/dd/1d/6cdd346605db62bde1f60954155e9ce48f4681c243f265b704\n","Successfully built Metaphone\n","Installing collected packages: Metaphone, rapidfuzz\n","Successfully installed Metaphone-0.6 rapidfuzz-3.6.1\n","Error during matching: 'set' object is not subscriptable\n","Phonetic matching completed. Results saved to: phonetic_matches.csv\n"]}],"source":["# Install necessary libraries\n","!pip install Metaphone rapidfuzz tqdm\n","\n","import requests\n","import csv\n","from metaphone import doublemetaphone\n","from rapidfuzz import fuzz\n","from tqdm import tqdm\n","\n","# Function to fetch word lists\n","def fetch_words(url):\n","    response = requests.get(url)\n","    if response.status_code == 200:\n","        return response.text.splitlines()\n","    return []\n","\n","# Improved pre-filtering: Exclude non-matching starting letters and similar length\n","def prefilter_words(english_words, french_words):\n","    filtered_english = set(english_words)\n","    filtered_french = set(word for word in french_words if word[0] in filtered_english and 3 < len(word) < 15)\n","    return filtered_english, filtered_french\n","\n","# Modified approximate_matching function with match count monitoring and error handling\n","def approximate_matching(english_words, french_words, threshold=70, batch_size=10000):\n","    potential_matches = []\n","    try:\n","        for i in range(0, len(english_words), batch_size):\n","            batch = english_words[i:i+batch_size]\n","            for eng_word in tqdm(batch, desc=f\"Batch {i//batch_size+1}\"):\n","                best_match = (None, 0)  # Tuple of (word, score)\n","                for fr_word in french_words:\n","                    if eng_word[0] != fr_word[0]:\n","                        continue\n","                    similarity_ratio = fuzz.ratio(eng_word, fr_word)\n","                    if similarity_ratio > best_match[1]:\n","                        best_match = (fr_word, similarity_ratio)\n","                if best_match[1] >= threshold:\n","                    potential_matches.append((eng_word, best_match[0], best_match[1]))\n","        print(f\"All words processed. Total matches found: {len(potential_matches)}\")\n","    except Exception as e:\n","        print(f\"Error during matching: {e}\")\n","    return potential_matches\n","\n","# URLs for English and French word lists\n","english_words_url = \"https://raw.githubusercontent.com/dwyl/english-words/master/words.txt\"\n","french_words_url = \"https://raw.githubusercontent.com/Taknok/French-Wordlist/master/francais.txt\"\n","\n","# Fetch word lists\n","english_words = fetch_words(english_words_url)\n","french_words = fetch_words(french_words_url)\n","\n","# Pre-filter words\n","english_words, french_words = prefilter_words(english_words, french_words)\n","\n","# Perform approximate matching without a top limit\n","potential_matches = approximate_matching(english_words, french_words)\n","\n","# File to save matches\n","output_file = \"phonetic_matches.csv\"\n","\n","# Save potential matches to file\n","with open(output_file, 'w', newline='', encoding='utf-8') as file:\n","    writer = csv.writer(file)\n","    writer.writerow([\"English Word\", \"French Word\", \"Similarity Score\"])  # Header\n","    for match in potential_matches:\n","        writer.writerow(match)\n","\n","print(\"Phonetic matching completed. Results saved to:\", output_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aLWK5BUtVxRs","outputId":"f77a3ee4-9919-4684-ed92-eb76978be65b","executionInfo":{"status":"ok","timestamp":1705525633812,"user_tz":0,"elapsed":515677,"user":{"displayName":"Rupert Murphy","userId":"07708960882595328857"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: Metaphone in /usr/local/lib/python3.10/dist-packages (0.6)\n","Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (3.6.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n"]},{"output_type":"stream","name":"stderr","text":["Approximate Matching: 100%|██████████| 466550/466550 [08:26<00:00, 920.26it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Phonetic matching completed. Results saved to: phonetic_matches.txt\n"]}],"source":["# Install necessary libraries\n","!pip install Metaphone rapidfuzz tqdm\n","\n","import requests\n","import csv\n","from metaphone import doublemetaphone\n","from rapidfuzz import fuzz\n","from tqdm import tqdm\n","\n","# Function to fetch word lists\n","def fetch_words(url):\n","    response = requests.get(url)\n","    if response.status_code == 200:\n","        return response.text.splitlines()\n","    return []\n","\n","# Improved pre-filtering: Exclude non-matching starting letters and similar length\n","def prefilter_words(english_words, french_words):\n","    filtered_english = set(english_words)\n","    filtered_french = set(word for word in french_words if word[0] in filtered_english and 3 < len(word) < 15)\n","    return filtered_english, filtered_french\n","\n","# Fast, Approximate Matching with Best Match Selection\n","def approximate_matching(english_words, french_words, top_n=50000, threshold=70):\n","    potential_matches = []\n","    for eng_word in tqdm(english_words, desc=\"Approximate Matching\"):\n","        best_match = (None, 0)  # Tuple of (word, score)\n","        for fr_word in french_words:\n","            if eng_word[0] != fr_word[0]:\n","                continue\n","            similarity_ratio = fuzz.ratio(eng_word, fr_word)\n","            if similarity_ratio > best_match[1]:\n","                best_mat6ch = (fr_word, similarity_ratio)\n","        if best_match[1] >= threshold:\n","            potential_matches.append((eng_word, best_match[0], best_match[1]))\n","    return potential_matches\n","\n","# URLs for English and French word lists\n","english_words_url = \"https://raw.githubusercontent.com/dwyl/english-words/master/words.txt\"\n","french_words_url = \"https://raw.githubusercontent.com/Taknok/French-Wordlist/master/francais.txt\"\n","\n","# Fetch word lists\n","english_words = fetch_words(english_words_url)\n","french_words = fetch_words(french_words_url)\n","\n","# Pre-filter words\n","english_words, french_words = prefilter_words(english_words, french_words)\n","\n","# Perform approximate matching\n","potential_matches = approximate_matching(english_words, french_words)\n","\n","# File to save matches with a different extension\n","output_file = \"phonetic_matches.txt\"\n","\n","# Save potential matches to file\n","with open(output_file, 'w', newline='', encoding='utf-8') as file:\n","    writer = csv.writer(file)\n","    writer.writerow([\"English Word\", \"French Word\", \"Similarity Score\"])  # Header\n","    for match in potential_matches:\n","        writer.writerow(match)\n","\n","print(\"Phonetic matching completed. Results saved to:\", output_file)"]},{"cell_type":"code","source":["import shutil\n","\n","# Specify the file name\n","file_name = \"phonetic_matches.txt\"\n","\n","# Define the download path (you can customize this)\n","download_path = \"/content/\" + file_name\n","\n","# Move the file to the download path\n","shutil.move(file_name, download_path)\n","\n","# Provide a direct download link\n","download_link = f'Click here to download the results: [phonetic_matches.txt]({download_path})'\n","\n","# Display the download link\n","print(download_link)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nv2TWfQvZIhQ","executionInfo":{"status":"ok","timestamp":1704655625641,"user_tz":0,"elapsed":24,"user":{"displayName":"Rupert Murphy","userId":"07708960882595328857"}},"outputId":"739f825e-9211-4a8d-b7fb-dcd8a0e8966d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Click here to download the results: [phonetic_matches.txt](/content/phonetic_matches.txt)\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","\n","# Your code to generate the text content here\n","text_content = \"This is the content of your text file.\"\n","\n","# Save the text content to a file\n","with open(\"output.txt\", \"w\") as text_file:\n","    text_file.write(text_content)\n","\n","# Trigger the download of the file\n","files.download(\"output.txt\")"],"metadata":{"id":"ev20eTe9ZxNV","executionInfo":{"status":"ok","timestamp":1704655802375,"user_tz":0,"elapsed":904,"user":{"displayName":"Rupert Murphy","userId":"07708960882595328857"}},"outputId":"ada477be-e44b-40eb-e82d-cfe1448624e2","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_ae0c2f28-925a-4d5e-90a1-70861f5e6604\", \"output.txt\", 38)"]},"metadata":{}}]},{"cell_type":"code","source":["import csv\n","from metaphone import doublemetaphone\n","from rapidfuzz import fuzz\n","from tqdm import tqdm\n","\n","# Function to perform phonetic matching with higher accuracy\n","def phonetic_matching(english_words, french_words, threshold=85):\n","    potential_matches = []\n","    for eng_word in tqdm(english_words, desc=\"Phonetic Matching\"):\n","        eng_phonetic = doublemetaphone(eng_word)\n","        for fr_word in french_words:\n","            fr_phonetic = doublemetaphone(fr_word)\n","            # Calculate the similarity ratio between the original words\n","            similarity_ratio = fuzz.ratio(eng_word, fr_word)\n","            if eng_phonetic == fr_phonetic and similarity_ratio >= threshold:\n","                potential_matches.append((eng_word, fr_word))\n","    return potential_matches\n","\n","# Read data from the CSV file\n","input_file = \"phonetic_matches.csv\"\n","with open(input_file, 'r', newline='', encoding='utf-8') as file:\n","    reader = csv.reader(file)\n","    next(reader)  # Skip the header row\n","    data = list(reader)\n","\n","# Extract English and French words from the CSV data\n","english_words = [row[0] for row in data]\n","french_words = [row[1] for row in data]\n","\n","# Perform phonetic matching with higher accuracy\n","potential_matches = phonetic_matching(english_words, french_words, threshold=90)\n","\n","# Display the results\n","for match in potential_matches:\n","    print(\"English Word:\", match[0])\n","    print(\"French Word:\", match[1])\n","    print()\n","\n","print(\"Phonetic matching with higher accuracy completed.\")"],"metadata":{"id":"U4Vc47SIiek4","colab":{"base_uri":"https://localhost:8080/","height":384},"executionInfo":{"status":"error","timestamp":1705437630496,"user_tz":0,"elapsed":211,"user":{"displayName":"Rupert Murphy","userId":"07708960882595328857"}},"outputId":"bd1f1dc7-7da7-4fd6-a7aa-267baad8d596"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'metaphone'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-fdcc0d75a3de>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmetaphone\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdoublemetaphone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrapidfuzz\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfuzz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'metaphone'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":[],"metadata":{"id":"mRFHxjQXN3SL"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNg/LL9jjWmKfWFaFN6szm3"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}